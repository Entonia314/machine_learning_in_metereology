{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e723abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression for Wind Gusts with predictors from ERA Interim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import lasso_path\n",
    "from sklearn.linear_model import LassoLarsCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e43d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ERA Interim Data in Dataframe (ERA_Interim_Wien.csv)\n",
    "# columns should be read in as floats, Date_Time as Int\n",
    "# Create DateTime Object from numerical Timestamp with format %Y%m%d%H\n",
    "# Set Date Column to Index of dataframe\n",
    "# Drop rows with NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4fca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Station Data from Vienna from Station_OBS_TT_FFX_Wien.csv\n",
    "# Create DateTime Object from numerical Timestamp with format %Y-%m-%d %H:%M \n",
    "# Set Date Column to Index\n",
    "# Drop rows with NaN values\n",
    "# Drop Temperature TT_Obs (because we will use FFX_Obs only) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd6e3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes based on the Date_Time column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a414b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all Correlations (directly on dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08073a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Correlation Plot with seaborn with white style\n",
    "# Generate a mask for the upper triangle\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "# Generate a custom diverging colormap (you can use sns.diverging_palette)\n",
    "# Draw the heatmap with the mask and correct aspect ratio, color range [-1,1]\n",
    "# Do not write correlation values into heatmap\n",
    "# Add title to plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "500220ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Linear regression \n",
    "\n",
    "# Create a StandardScaler object with all columns (including predictand)\n",
    "# Create new datframe containing the scaled predictors and predictand \n",
    "# Add Date_Time column to dataframe and set it to the index of the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d032bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictand (FFX_Obs) and all other columns as predictors \n",
    "# Create variable y for predictand\n",
    "# Create variable Matrix X for predictors\n",
    "# Create variable features as a list with predictor names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf51a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in Trainings- and Testdata using train_test_split (here it is important to take large test size of 95-98 %)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cda35a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Linear Regression using LinearRegression()\n",
    "# Compute y hat variables for Training and Test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c5e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a Scatterplot for original (y) and modelled (y hat) predictand \n",
    "# Plot results for training- and testdata in same scatterplot using different colors\n",
    "# Add a legend\n",
    "# Add xlabel, ylabel and a title\n",
    "# Optional: scale back Windgusts to original values (instead of mean = 0, variance = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4142c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of Verification Scores\n",
    "# BIAS, MAE, MSE, RMSE, R² (explained Variance) for Test and Training Data\n",
    "# print results as Text\n",
    "# Optional: do this for rescaled y and y hat variables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd70a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Ridge Regression with alphas (in our slides lambda) between 10⁻⁴ and 10⁴ (logarithmically spaced) using 100 values\n",
    "\n",
    "# Create loop over all alpha values and compute for all ridge regression using linear_model.Ridge\n",
    "# Intercep is excluded because of standardizing also wind gusts, therefore  fit_intercept=False\n",
    "# Compute for all alphas MSE for Test and Training Data, for Training Data also RSS \n",
    "# Collect all coefficients for individual alphas to draw the Ridge-Path\n",
    "# Optional: compute effective degree of freedom based on last equation of slide 26 (can be used for plots instead of alpha or lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acf7d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Ridge Path as function of alpha / lambda or effective degree of freedom (optional), see slide 27, figures at the right\n",
    "# Define colormap jet and take len(features) colors for individual lines (coefficients)\n",
    "# Optional: define diverse linestyles to discriminate large numbers of predictors\n",
    "\n",
    "# Add legend with predictor names outside the axis\n",
    "# Add xlabel, ylabel and title\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2594e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of Training and Test-MSE as a function of alpha resp. lambda or effectice degree of freedom (optional)\n",
    "# add legend, xlabel, ylabel and title\n",
    "# add vertical line at position with lowest test error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "113df77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "# Plot RSS, lambda*beta^T*beta and sum of both as function of lambda / alpha or degree of freedom for Trainings Data\n",
    "# Add legend, xlabel, ylabel and title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c36ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO Regression\n",
    "# Create 100 alpha (lambda) values logarithmically spaced between 10⁻² and 10¹\n",
    "# Compute Lasso Path using lasso_path, return variables are alphas and coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3e93276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot LASSO Path as function of alpha (lambda)\n",
    "# Define colormap jet and take len(features) colors for individual lines (coefficients)\n",
    "# define diverse linestyles to discriminate large numbers of predictors (optional)\n",
    "# Add legend with predictor names outside the axis\n",
    "# Add xlabel, ylabel and title\n",
    "# invert xaxis for decreasing values of alpha (lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30557560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: LASSO Regression with Cross Validation\n",
    "# Create model using LassoLarsCV with 10 fold Crossvalidation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e70da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Plot MSE Errors for individual Crossvalidations\n",
    "# use logarithmic x-axis and reverse it for decreasing alpha (lambda)\n",
    "# plot also mean value of MSE Errors as function of alpha (lambda)\n",
    "# Compute standard error for Crossvalidation MSE using equations on slide 35\n",
    "# plot confidence interval for MSE using computed standard error\n",
    "# plot vertical lines for alpha with minimal MSE\n",
    "# plot horizontal line for MSE_min + SE\n",
    "# plot vertical line for that alpha which corresponds to MSE = MSE_min + SE (stronger regularized model), see also plot on slide 36\n",
    "# add legend, xlabel, ylabel and title\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "091a54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Plot LASSO Path with results from LassoLarsCV\n",
    "# Plot only LASSO Path for features with coefficients unequal 0 between maximal alpha and alpha which corresponds to MSE = MSE_min + SE\n",
    "# Add vertical line for alphas with minimal MSE and for MSE_min + SE (best solution in terms of one standard error rule)\n",
    "# Add legend, xlabel, ylabel and title\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
